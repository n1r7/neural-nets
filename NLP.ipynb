{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/n1r7/Downloads/PYTORCH_NOTEBOOKS/Data/shakespeare.txt','r',encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl mak'st waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the world's due, by the grave and thee.\\n\\n\\n                     2\\n  When forty winters shall besiege thy brow,\\n  And dig deep trenches in thy beauty's field,\\n  Thy youth's proud livery so gazed on now,\\n  Will be a tattered weed of small worth held:  \\n  Then being asked, where all thy beauty lies,\\n  Where all the treasure of thy lusty days;\\n  To say within thine own deep su\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep su\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text) # number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text at character level\n",
    "\n",
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder that takes character and returns number\n",
    "# Create decoder that takes number and returns character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num ---> letter\n",
    "# for pair in enumerate(all_characters):\n",
    "#     print(pair)\n",
    "\n",
    "decoder = dict(enumerate(all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'e',\n",
       " 1: 'c',\n",
       " 2: ')',\n",
       " 3: 'U',\n",
       " 4: '3',\n",
       " 5: '.',\n",
       " 6: 'r',\n",
       " 7: 'A',\n",
       " 8: 'V',\n",
       " 9: 'm',\n",
       " 10: 'B',\n",
       " 11: '<',\n",
       " 12: 'q',\n",
       " 13: 'f',\n",
       " 14: ' ',\n",
       " 15: 'C',\n",
       " 16: 'i',\n",
       " 17: 'I',\n",
       " 18: 'X',\n",
       " 19: 'Q',\n",
       " 20: 'T',\n",
       " 21: ';',\n",
       " 22: 'x',\n",
       " 23: 'o',\n",
       " 24: '[',\n",
       " 25: 'h',\n",
       " 26: '-',\n",
       " 27: 'W',\n",
       " 28: 'Y',\n",
       " 29: 'b',\n",
       " 30: 'w',\n",
       " 31: '9',\n",
       " 32: '1',\n",
       " 33: '!',\n",
       " 34: 'N',\n",
       " 35: 'M',\n",
       " 36: '}',\n",
       " 37: 's',\n",
       " 38: 'y',\n",
       " 39: 'S',\n",
       " 40: '&',\n",
       " 41: '\\n',\n",
       " 42: 'v',\n",
       " 43: 'L',\n",
       " 44: '6',\n",
       " 45: 'J',\n",
       " 46: 'k',\n",
       " 47: 'G',\n",
       " 48: '8',\n",
       " 49: 'F',\n",
       " 50: '7',\n",
       " 51: 'R',\n",
       " 52: 'a',\n",
       " 53: '2',\n",
       " 54: '?',\n",
       " 55: '`',\n",
       " 56: 'H',\n",
       " 57: \"'\",\n",
       " 58: 'P',\n",
       " 59: '|',\n",
       " 60: 'n',\n",
       " 61: 'p',\n",
       " 62: 'D',\n",
       " 63: '0',\n",
       " 64: ',',\n",
       " 65: '4',\n",
       " 66: 'u',\n",
       " 67: 'l',\n",
       " 68: 'E',\n",
       " 69: '>',\n",
       " 70: 't',\n",
       " 71: 'j',\n",
       " 72: ']',\n",
       " 73: 'K',\n",
       " 74: '_',\n",
       " 75: 'd',\n",
       " 76: '(',\n",
       " 77: '\"',\n",
       " 78: '5',\n",
       " 79: 'g',\n",
       " 80: ':',\n",
       " 81: 'O',\n",
       " 82: 'z',\n",
       " 83: 'Z'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter ---> num\n",
    "encoder = {char: ind for ind,char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 0,\n",
       " 'c': 1,\n",
       " ')': 2,\n",
       " 'U': 3,\n",
       " '3': 4,\n",
       " '.': 5,\n",
       " 'r': 6,\n",
       " 'A': 7,\n",
       " 'V': 8,\n",
       " 'm': 9,\n",
       " 'B': 10,\n",
       " '<': 11,\n",
       " 'q': 12,\n",
       " 'f': 13,\n",
       " ' ': 14,\n",
       " 'C': 15,\n",
       " 'i': 16,\n",
       " 'I': 17,\n",
       " 'X': 18,\n",
       " 'Q': 19,\n",
       " 'T': 20,\n",
       " ';': 21,\n",
       " 'x': 22,\n",
       " 'o': 23,\n",
       " '[': 24,\n",
       " 'h': 25,\n",
       " '-': 26,\n",
       " 'W': 27,\n",
       " 'Y': 28,\n",
       " 'b': 29,\n",
       " 'w': 30,\n",
       " '9': 31,\n",
       " '1': 32,\n",
       " '!': 33,\n",
       " 'N': 34,\n",
       " 'M': 35,\n",
       " '}': 36,\n",
       " 's': 37,\n",
       " 'y': 38,\n",
       " 'S': 39,\n",
       " '&': 40,\n",
       " '\\n': 41,\n",
       " 'v': 42,\n",
       " 'L': 43,\n",
       " '6': 44,\n",
       " 'J': 45,\n",
       " 'k': 46,\n",
       " 'G': 47,\n",
       " '8': 48,\n",
       " 'F': 49,\n",
       " '7': 50,\n",
       " 'R': 51,\n",
       " 'a': 52,\n",
       " '2': 53,\n",
       " '?': 54,\n",
       " '`': 55,\n",
       " 'H': 56,\n",
       " \"'\": 57,\n",
       " 'P': 58,\n",
       " '|': 59,\n",
       " 'n': 60,\n",
       " 'p': 61,\n",
       " 'D': 62,\n",
       " '0': 63,\n",
       " ',': 64,\n",
       " '4': 65,\n",
       " 'u': 66,\n",
       " 'l': 67,\n",
       " 'E': 68,\n",
       " '>': 69,\n",
       " 't': 70,\n",
       " 'j': 71,\n",
       " ']': 72,\n",
       " 'K': 73,\n",
       " '_': 74,\n",
       " 'd': 75,\n",
       " '(': 76,\n",
       " '\"': 77,\n",
       " '5': 78,\n",
       " 'g': 79,\n",
       " ':': 80,\n",
       " 'O': 81,\n",
       " 'z': 82,\n",
       " 'Z': 83}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 32, 41, 14, 14, 49,  6, 23,  9, 14, 13, 52, 16,\n",
       "        6,  0, 37, 70, 14,  1,  6,  0, 52, 70, 66,  6,  0, 37, 14, 30,  0,\n",
       "       14, 75,  0, 37, 16,  6,  0, 14, 16, 60,  1,  6,  0, 52, 37,  0, 64,\n",
       "       41, 14, 14, 20, 25, 52, 70, 14, 70, 25,  0,  6,  0, 29, 38, 14, 29,\n",
       "        0, 52, 66, 70, 38, 57, 37, 14,  6, 23, 37,  0, 14,  9, 16, 79, 25,\n",
       "       70, 14, 60,  0, 42,  0,  6, 14, 75, 16,  0, 64, 41, 14, 14, 10, 66,\n",
       "       70, 14, 52, 37, 14, 70, 25,  0, 14,  6, 16, 61,  0,  6, 14, 37, 25,\n",
       "       23, 66, 67, 75, 14, 29, 38, 14, 70, 16,  9,  0, 14, 75,  0,  1,  0,\n",
       "       52, 37,  0, 64, 41, 14, 14, 56, 16, 37, 14, 70,  0, 60, 75,  0,  6,\n",
       "       14, 25,  0, 16,  6, 14,  9, 16, 79, 25, 70, 14, 29,  0, 52,  6, 14,\n",
       "       25, 16, 37, 14,  9,  0,  9, 23,  6, 38, 80, 41, 14, 14, 10, 66, 70,\n",
       "       14, 70, 25, 23, 66, 14,  1, 23, 60, 70,  6, 52,  1, 70,  0, 75, 14,\n",
       "       70, 23, 14, 70, 25, 16, 60,  0, 14, 23, 30, 60, 14, 29,  6, 16, 79,\n",
       "       25, 70, 14,  0, 38,  0, 37, 64, 41, 14, 14, 49,  0,  0, 75, 57, 37,\n",
       "       70, 14, 70, 25, 38, 14, 67, 16, 79, 25, 70, 57, 37, 14, 13, 67, 52,\n",
       "        9,  0, 14, 30, 16, 70, 25, 14, 37,  0, 67, 13, 26, 37, 66, 29, 37,\n",
       "       70, 52, 60, 70, 16, 52, 67, 14, 13, 66,  0, 67, 64, 41, 14, 14, 35,\n",
       "       52, 46, 16, 60, 79, 14, 52, 14, 13, 52,  9, 16, 60,  0, 14, 30, 25,\n",
       "        0,  6,  0, 14, 52, 29, 66, 60, 75, 52, 60,  1,  0, 14, 67, 16,  0,\n",
       "       37, 64, 41, 14, 14, 20, 25, 38, 14, 37,  0, 67, 13, 14, 70, 25, 38,\n",
       "       14, 13, 23,  0, 64, 14, 70, 23, 14, 70, 25, 38, 14, 37, 30,  0,  0,\n",
       "       70, 14, 37,  0, 67, 13, 14, 70, 23, 23, 14,  1,  6, 66,  0, 67, 80,\n",
       "       41, 14, 14, 20, 25, 23, 66, 14, 70, 25, 52, 70, 14, 52,  6, 70, 14,\n",
       "       60, 23, 30, 14, 70, 25,  0, 14, 30, 23,  6, 67, 75, 57, 37, 14, 13,\n",
       "        6,  0, 37, 25, 14, 23,  6, 60, 52,  9,  0, 60, 70, 64, 41, 14, 14,\n",
       "        7, 60, 75, 14, 23, 60, 67, 38, 14, 25,  0,  6, 52, 67, 75, 14, 70,\n",
       "       23, 14, 70, 25,  0, 14, 79, 52, 66, 75, 38, 14, 37, 61,  6, 16, 60,\n",
       "       79, 64, 41, 14, 14, 27, 16, 70, 25, 16, 60, 14, 70, 25, 16, 60,  0,\n",
       "       14, 23, 30, 60, 14, 29, 66])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data\n",
    "\n",
    "def one_hot_encoder(encoded_text,num_uni_chars):\n",
    "    \n",
    "    # encoded_text ---> batch of encoded text\n",
    "    # num_uni_chars ---> len(set(text))\n",
    "    \n",
    "    # create placeholder for 0s\n",
    "    one_hot = np.zeros((encoded_text.size,num_uni_chars))\n",
    "    \n",
    "    # convert data type so we can use pytorch\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "    \n",
    "    # use fancy indexing to fill in the 1s at correct index location\n",
    "    one_hot[np.arange(one_hot.shape[0]),encoded_text.flatten()] = 1.0\n",
    "    \n",
    "    one_hot = one_hot.reshape((*encoded_text.shape,num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one_hot_encoder\n",
    "arr = np.array([1,2,0])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(arr,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = np.arange(10)\n",
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch generator function\n",
    "\n",
    "def generate_batches(encoded_text,samp_per_batch=10,seq_len=50):\n",
    "    \n",
    "    # X : encoded text of length seq_len\n",
    "    # Y : encoded text shifted by one\n",
    "    \n",
    "    # number of characters per batch\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    # how many batches can be made given the len of encoded text\n",
    "    num_batches_avail = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    # cut off end of encoded text that won't fit evenly in a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail*char_per_batch]\n",
    "    \n",
    "    encoded_text = encoded_text.reshape((samp_per_batch,-1))\n",
    "    \n",
    "    for n in range(0,encoded_text.shape[1],seq_len):\n",
    "        \n",
    "        x = encoded_text[:,n:n+seq_len]\n",
    "        \n",
    "        # create zeros array same shape as x\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            y[:,:-1] = x[:,1:]\n",
    "            y[:,-1] = encoded_text[:,n+seq_len]\n",
    "        \n",
    "        except:\n",
    "            y[:,:-1] = x[:,1:]\n",
    "            y[:,-1] = encoded_text[:,0]\n",
    "            \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = np.arange(20)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text,samp_per_batch=2,seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,all_chars,num_hidden=256,num_layers=4,drop_prob=0.5,use_gpu=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char:ind for ind,char in decoder.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars),num_hidden,num_layers,dropout=drop_prob,batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden,len(self.all_chars))\n",
    "    \n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "        \n",
    "        lstm_output,hidden = self.lstm(x,hidden)\n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output = drop_output.contiguous().view(-1,self.num_hidden) # reshape for final layer\n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "        \n",
    "        return final_out,hidden\n",
    "    \n",
    "    \n",
    "    def hidden_state(self,batch_size):\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n",
    "                      torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n",
    "                      torch.zeros(self.num_layers,batch_size,self.num_hidden))\n",
    "        \n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(all_chars=all_characters,\n",
    "                 num_hidden=512,\n",
    "                 num_layers=3,\n",
    "                 drop_prob=0.5,\n",
    "                 use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharModel(\n",
       "  (lstm): LSTM(84, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc_linear): Linear(in_features=512, out_features=84, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172032, 1048576, 2048, 2048, 1048576, 1048576, 2048, 2048, 1048576, 1048576, 2048, 2048, 43008, 84]\n",
      "\n",
      "\n",
      "5470292\n"
     ]
    }
   ],
   "source": [
    "total_param = []\n",
    "\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))\n",
    "    \n",
    "print(total_param)\n",
    "print(\"\\n\")\n",
    "print(sum(total_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.1\n",
    "\n",
    "train_ind = int(len(encoded_text)*train_percent)\n",
    "\n",
    "train_data = encoded_text[:train_ind]\n",
    "val_data = encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544560"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4901049"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4901048"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(encoded_text) * train_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 100\n",
    "\n",
    "seq_len = 100\n",
    "\n",
    "tracker = 0\n",
    "\n",
    "num_char = max(encoded_text)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Step: 25 Val Loss: 3.189283847808838\n",
      "Epoch: 0 Step: 50 Val Loss: 3.1906490325927734\n"
     ]
    }
   ],
   "source": [
    "# Set model to train\n",
    "model.train()\n",
    "\n",
    "\n",
    "# Check to see if using GPU\n",
    "if model.use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    hidden = model.hidden_state(batch_size)\n",
    "    \n",
    "    \n",
    "    for x,y in generate_batches(train_data,batch_size,seq_len):\n",
    "        \n",
    "        tracker += 1\n",
    "        \n",
    "        # One Hot Encode incoming data\n",
    "        x = one_hot_encoder(x,num_char)\n",
    "        \n",
    "        # Convert Numpy Arrays to Tensor\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        targets = torch.from_numpy(y)\n",
    "        \n",
    "        # Adjust for GPU if necessary\n",
    "        \n",
    "        if model.use_gpu:\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "        # Reset Hidden State\n",
    "        # If we dont' reset we would backpropagate through all training history\n",
    "        hidden = tuple([state.data for state in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        lstm_output, hidden = model.forward(inputs,hidden)\n",
    "        loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # POSSIBLE EXPLODING GRADIENT PROBLEM!\n",
    "        # LET\"S CLIP JUST IN CASE\n",
    "        nn.utils.clip_grad_norm_(model.parameters(),max_norm=5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        ### CHECK ON VALIDATION SET ######\n",
    "        #################################\n",
    "        \n",
    "        if tracker % 25 == 0:\n",
    "            \n",
    "            val_hidden = model.hidden_state(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x,y in generate_batches(val_data,batch_size,seq_len):\n",
    "                \n",
    "                # One Hot Encode incoming data\n",
    "                x = one_hot_encoder(x,num_char)\n",
    "                \n",
    "\n",
    "                # Convert Numpy Arrays to Tensor\n",
    "\n",
    "                inputs = torch.from_numpy(x)\n",
    "                targets = torch.from_numpy(y)\n",
    "\n",
    "                # Adjust for GPU if necessary\n",
    "\n",
    "                if model.use_gpu:\n",
    "\n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "                    \n",
    "                # Reset Hidden State\n",
    "                # If we dont' reset we would backpropagate through \n",
    "                # all training history\n",
    "                val_hidden = tuple([state.data for state in val_hidden])\n",
    "                \n",
    "                lstm_output, val_hidden = model.forward(inputs,val_hidden)\n",
    "                val_loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            # Reset to training model after val for loop\n",
    "            model.train()\n",
    "            \n",
    "            print(f\"Epoch: {i} Step: {tracker} Val Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
